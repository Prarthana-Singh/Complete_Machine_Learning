
---

##  **Basic-Level KNN Questions**

1. What is the K-Nearest Neighbors (KNN) algorithm?
2. Is KNN a classification or regression algorithm?
3. How does KNN work — explain step by step.
4. What is the role of the parameter **‘K’** in KNN?
5. How do you choose the optimal value of **K**?
6. What happens if you choose **K = 1** or **K = very large**?
7. Is KNN a **parametric** or **non-parametric** algorithm? Why?
8. Why is KNN considered a **lazy learner**?
9. What do you mean by **instance-based learning** in KNN?
10. In what situations would you prefer using KNN?

---

##  **Distance Metrics & Working**

11. What distance metrics are used in KNN?
12. When would you use **Euclidean distance** vs **Manhattan distance**?
13. Can you use **Cosine similarity** in KNN?
14. What is the effect of **feature scaling** on KNN performance?
15. Why do we need to **normalize or standardize** data before using KNN?
16. How does **dimensionality** affect the distance calculation in KNN?

---

##  **Performance & Complexity**

17. What is the **time complexity** of KNN during training and prediction?
18. Why is KNN **slow at prediction time** but fast during training?
19. How can we improve the **efficiency** of KNN for large datasets?
20. What data structures can optimize KNN searches (like KD-trees, Ball-trees)?
21. How does **curse of dimensionality** impact KNN performance?
22. What are some **disadvantages** of using KNN?
23. How can you handle **large datasets** efficiently with KNN?

---

##  **Model Evaluation & Tuning**

24. How do you evaluate the performance of a KNN classifier?
25. Which metrics would you use for KNN regression and classification?
26. How do you tune the value of **K** using cross-validation?
27. How do you handle **imbalanced datasets** in KNN?
28. What’s the impact of **noisy data** or **outliers** on KNN performance?
29. How can you improve KNN accuracy on noisy data?
30. Would you use **feature selection** before applying KNN? Why or why not?

---

##  **KNN in Practice**

31. Give a real-world example where KNN can be effectively used.
32. Can you use KNN for **recommendation systems**?
33. How does KNN differ from algorithms like **Logistic Regression** or **SVM**?
34. Can KNN be used for **multi-class classification** problems?
35. How does KNN handle **missing values** in the dataset?
36. How would you implement KNN from scratch in Python?
37. Which scikit-learn class is used to implement KNN? (→ `KNeighborsClassifier`, `KNeighborsRegressor`)
38. What parameters can you tune in scikit-learn’s `KNeighborsClassifier`?
39. How do you visualize decision boundaries in KNN?
40. What is the **bias-variance tradeoff** in the context of KNN?

---

##  **Advanced / Conceptual**

41. How can **weighted KNN** improve performance?
42. What are the pros and cons of using **distance weighting**?
43. How does **KNN regression** work?
44. What happens if your dataset has **categorical features**?
45. Can KNN handle **mixed-type data** (numerical + categorical)?
46. How do you interpret KNN in terms of **Bayesian decision theory**?
47. What are some variants of KNN (like **Radius Neighbors**, **Fuzzy KNN**, etc.)?
48. How do you deal with **high-dimensional data** in KNN?
49. What happens when features are **highly correlated**?
50. How do you perform **feature importance** analysis with KNN?

---

##  **Tricky & Application-Based**

51. Suppose you increase K from 3 to 15 — what effect will it have on bias and variance?
52. If your dataset is **highly imbalanced**, how will KNN behave?
53. How would you select features for KNN in a dataset with 1000 features?
54. Why might KNN perform poorly on sparse data (like text)?
55. How would you use KNN for **anomaly detection**?
56. What’s the difference between **K-means** and **KNN**?
57. Can KNN be used for **online learning** or **streaming data**?
58. Why is KNN sensitive to **irrelevant features**?
59. What happens if all features are not on the same scale?
60. Can KNN model **non-linear decision boundaries**?

---

