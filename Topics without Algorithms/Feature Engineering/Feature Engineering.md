
---

##  **Basic Level Questions**

1. What is Feature Engineering?
2. Why is Feature Engineering important in machine learning?
3. What are the different steps involved in Feature Engineering?
4. How does Feature Engineering improve model performance?
5. What are the differences between Feature Engineering and Feature Selection?
6. Can you explain the difference between raw data and engineered features?
7. What are derived features? Give examples.
8. What is the goal of Feature Engineering?
9. Why is domain knowledge important for Feature Engineering?
10. What are some common challenges in Feature Engineering?

---

##  **Data Transformation and Encoding**

11. What are categorical features?
12. How do you handle categorical variables?
13. Difference between **Label Encoding** and **One-Hot Encoding**?
14. When would you prefer Label Encoding over One-Hot Encoding?
15. What is **Ordinal Encoding** and when should it be used?
16. How do you handle high-cardinality categorical features?
17. What are **Target Encoding** and its pros and cons?
18. What is **Frequency Encoding** and when is it used?
19. What is **Binary Encoding** and why is it used?
20. What are **dummy variable traps** and how do you avoid them?

---

##  **Feature Scaling and Normalization**

21. What is feature scaling and why is it important?
22. Difference between **Normalization** and **Standardization**?
23. What are **Min-Max Scaling** and **Z-Score Scaling**?
24. When should you normalize data?
25. When is standardization preferred over normalization?
26. What happens if you don’t scale your features?
27. How do you handle scaling in datasets with both categorical and numerical features?

---

##  **Feature Creation and Extraction**

28. What is Feature Extraction?
29. What is the difference between Feature Extraction and Feature Creation?
30. What are **polynomial features** and when are they used?
31. How do you handle **datetime features** (e.g., extracting year, month, weekday)?
32. How would you engineer features from **text data**?
33. How do you create features from **image data**?
34. What is **dimensionality reduction** in the context of Feature Engineering?
35. What are some **feature extraction techniques** you know?
36. Explain **PCA (Principal Component Analysis)** in simple terms.
37. What are **embedding techniques** in NLP (e.g., Word2Vec, TF-IDF, BERT embeddings)?

---

##  **Handling Missing and Outlier Data**

38. How do you handle missing values during Feature Engineering?
39. What are the different imputation techniques?
40. How do you decide whether to drop or impute missing values?
41. How do outliers affect your model?
42. What are some common methods for handling outliers?
43. What is **Winsorization**?
44. What is the **IQR method** for outlier detection?

---

##  **Advanced & Conceptual Questions**

45. How do you decide which features to create for a problem?
46. Can Feature Engineering lead to **data leakage**? Give examples.
47. How do you detect and prevent **data leakage** during Feature Engineering?
48. How do you deal with correlated features?
49. How can Feature Engineering help reduce model overfitting?
50. How can Feature Engineering improve model interpretability?
51. How does Feature Engineering differ for linear models vs tree-based models?
52. What are **interaction features** and when should you create them?
53. How can Feature Engineering help in **imbalanced datasets**?
54. Can Feature Engineering be automated? If yes, how?
55. What tools or libraries can you use for automated Feature Engineering? (e.g., Featuretools, Autofeat)

---

##  **Practical / Scenario-Based Questions**

56. Suppose you have a dataset with categorical, numerical, and datetime columns — describe your Feature Engineering pipeline.
57. You have a dataset with 50% missing values — what steps will you take before modeling?
58. How would you engineer features for predicting **house prices**?
59. How would you create features from **transaction data**?
60. How would you handle **text data** in a classification task?
61. If your model is not performing well, how would you use Feature Engineering to improve it?
62. How do you ensure reproducibility in Feature Engineering?
63. How do you handle unseen categorical values during inference?
64. How do you ensure that Feature Engineering on training and test data is consistent?
65. What Feature Engineering steps are commonly used in time-series forecasting?

---

##  **Bonus — Interview-Style Tricky Questions**

66. Can Feature Engineering increase bias?
67. Is Feature Engineering needed if you are using Deep Learning?
68. What’s the difference between Feature Engineering for linear regression and for decision trees?
69. Why does Feature Engineering sometimes reduce variance?
70. How would you evaluate if a newly engineered feature actually helps?

---

